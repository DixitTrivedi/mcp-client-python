[
  {
    "role": "user",
    "content": "How do I connect langchain and chromadb"
  },
  {
    "role": "assistant",
    "content": [
      {
        "text": "Let me search the Langchain documentation to find the details about connecting Langchain and ChromaDB.",
        "type": "text"
      },
      {
        "id": "toolu_01JqPkWyDQi4SWKXcEe6dXEv",
        "input": {
          "query": "ChromaDB vector store integration",
          "library": "langchain"
        },
        "name": "get_docs",
        "type": "tool_use"
      }
    ]
  },
  {
    "role": "user",
    "content": [
      {
        "type": "tool_result",
        "tool_use_id": "toolu_01JqPkWyDQi4SWKXcEe6dXEv",
        "content": [
          "type='text' text='\\n\\n\\n\\n\\nChroma | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGreenNodeGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)SurrealDBNebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTensorlakeTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksIBM Db2 Vector Store and Vector SearchDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBVectorStoreTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientGreenNodeHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsVector storesChromaOn this pageChroma\\nThis notebook covers how to get started with the Chroma vector store.\\n\\nChroma is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of Chroma at this page, and find the API reference for the LangChain integration at this page.\\n\\nSetup\\u200b\\nTo access Chroma vector stores you\\'ll need to install the langchain-chroma integration package.\\npip install -qU \"langchain-chroma>=0.1.2\"\\nCredentials\\u200b\\nYou can use the Chroma vector store without any credentials, simply installing the package above is enough!\\nIf you want to get best in-class automated tracing of your model calls you can also set your LangSmith API key by uncommenting below:\\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nInitialization\\u200b\\nBasic Initialization\\u200b\\nBelow is a basic initialization, including the use of a directory to save the data locally.\\n\\nSelect embeddings model:OpenAI\u25beOpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get(\"OPENAI_API_KEY\"):  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\\nfrom langchain_chroma import Chromavector_store = Chroma(    collection_name=\"example_collection\",    embedding_function=embeddings,    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary)\\nInitialization from client\\u200b\\nYou can also initialize from a Chroma client, which is particularly useful if you want easier access to the underlying database.\\nimport chromadbpersistent_client = chromadb.PersistentClient()collection = persistent_client.get_or_create_collection(\"collection_name\")collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])vector_store_from_client = Chroma(    client=persistent_client,    collection_name=\"collection_name\",    embedding_function=embeddings,)\\nManage vector store\\u200b\\nOnce you have created your vector store, we can interact with it by adding and deleting different items.\\nAdd items to vector store\\u200b\\nWe can add items to our vector store by using the add_documents function.\\nfrom uuid import uuid4from langchain_core.documents import Documentdocument_1 = Document(    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",    metadata={\"source\": \"tweet\"},    id=1,)document_2 = Document(    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",    metadata={\"source\": \"news\"},    id=2,)document_3 = Document(    page_content=\"Building an exciting new project with LangChain - come check it out!\",    metadata={\"source\": \"tweet\"},    id=3,)document_4 = Document(    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",    metadata={\"source\": \"news\"},    id=4,)document_5 = Document(    page_content=\"Wow! That was an amazing movie. I can\\'t wait to see it again.\",    metadata={\"source\": \"tweet\"},    id=5,)document_6 = Document(    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",    metadata={\"source\": \"website\"},    id=6,)document_7 = Document(    page_content=\"The top 10 soccer players in the world right now.\",    metadata={\"source\": \"website\"},    id=7,)document_8 = Document(    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",    metadata={\"source\": \"tweet\"},    id=8,)document_9 = Document(    page_content=\"The stock market is down 500 points today due to fears of a recession.\",    metadata={\"source\": \"news\"},    id=9,)document_10 = Document(    page_content=\"I have a bad feeling I am going to get deleted :(\",    metadata={\"source\": \"tweet\"},    id=10,)documents = [    document_1,    document_2,    document_3,    document_4,    document_5,    document_6,    document_7,    document_8,    document_9,    document_10,]uuids = [str(uuid4()) for _ in range(len(documents))]vector_store.add_documents(documents=documents, ids=uuids)API Reference:Document\\n[\\'f22ed484-6db3-4b76-adb1-18a777426cd6\\', \\'e0d5bab4-6453-4511-9a37-023d9d288faa\\', \\'877d76b8-3580-4d9e-a13f-eed0fa3d134a\\', \\'26eaccab-81ce-4c0a-8e76-bf542647df18\\', \\'bcaa8239-7986-4050-bf40-e14fb7dab997\\', \\'cdc44b38-a83f-4e49-b249-7765b334e09d\\', \\'a7a35354-2687-4bc2-8242-3849a4d18d34\\', \\'8780caf1-d946-4f27-a707-67d037e9e1d8\\', \\'dec6af2a-7326-408f-893d-7d7d717dfda9\\', \\'3b18e210-bb59-47a0-8e17-c8e51176ea5e\\']\\nUpdate items in vector store\\u200b\\nNow that we have added documents to our vector store, we can update existing documents by using the update_documents function.\\nupdated_document_1 = Document(    page_content=\"I had chocolate chip pancakes and fried eggs for breakfast this morning.\",    metadata={\"source\": \"tweet\"},    id=1,)updated_document_2 = Document(    page_content=\"The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees.\",    metadata={\"source\": \"news\"},    id=2,)vector_store.update_document(document_id=uuids[0], document=updated_document_1)# You can also update multiple documents at oncevector_store.update_documents(    ids=uuids[:2], documents=[updated_document_1, updated_document_2])\\nDelete items from vector store\\u200b\\nWe can also delete items from our vector store as follows:\\nvector_store.delete(ids=uuids[-1])\\nQuery vector store\\u200b\\nOnce your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.\\nQuery directly\\u200b\\nSimilarity search\\u200b\\nPerforming a simple similarity search can be done as follows:\\nresults = vector_store.similarity_search(    \"LangChain provides abstractions to make working with LLMs easy\",    k=2,    filter={\"source\": \"tweet\"},)for res in results:    print(f\"* {res.page_content} [{res.metadata}]\")\\n* Building an exciting new project with LangChain - come check it out! [{\\'source\\': \\'tweet\\'}]* LangGraph is the best framework for building stateful, agentic applications! [{\\'source\\': \\'tweet\\'}]\\nSimilarity search with score\\u200b\\nIf you want to execute a similarity search and receive the corresponding scores you can run:\\nresults = vector_store.similarity_search_with_score(    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"})for res, score in results:    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")\\n* [SIM=1.726390] The stock market is down 500 points today due to fears of a recession. [{\\'source\\': \\'news\\'}]\\nSearch by vector\\u200b\\nYou can also search by vector:\\nresults = vector_store.similarity_search_by_vector(    embedding=embeddings.embed_query(\"I love green eggs and ham!\"), k=1)for doc in results:    print(f\"* {doc.page_content} [{doc.metadata}]\")\\n* I had chocolate chip pancakes and fried eggs for breakfast this morning. [{\\'source\\': \\'tweet\\'}]\\nOther search methods\\u200b\\nThere are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for AstraDBVectorStore check out the API reference.\\nQuery by turning into retriever\\u200b\\nYou can also transform the vector store into a retriever for easier usage in your chains. For more information on the different search types and kwargs you can pass, please visit the API reference here.\\nretriever = vector_store.as_retriever(    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5})retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})\\n[Document(metadata={\\'source\\': \\'news\\'}, page_content=\\'Robbers broke into the city bank and stole $1 million in cash.\\')]\\nUsage for retrieval-augmented generation\\u200b\\nFor guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\\nTutorials\\nHow-to: Question and answer with RAG\\nRetrieval conceptual docs\\n\\nAPI reference\\u200b\\nFor detailed documentation of all Chroma vector store features and configurations head to the API reference: https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html\\nRelated\\u200b\\n\\nVector store conceptual guide\\nVector store how-to guides\\nEdit this pagePreviousApache CassandraNextClarifaiSetupCredentialsInitializationBasic InitializationInitialization from clientManage vector storeAdd items to vector storeUpdate items in vector storeDelete items from vector storeQuery vector storeQuery directlyQuery by turning into retrieverUsage for retrieval-augmented generationAPI referenceRelatedCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nChroma | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGreenNodeGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)SurrealDBNebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTensorlakeTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversDeep LakeAstra DBChromaDashVectorDatabricks Vector SearchDingoDBElasticsearchSAP HANA Cloud Vector EngineMilvusMongoDB AtlasMyScaleNeo4jOpenSearchPGVector (Postgres)PineconeQdrantRedisSupabase (Postgres)Tencent Cloud VectorDBTimescale Vector (Postgres)Vectara self-queryingWeaviateSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksIBM Db2 Vector Store and Vector SearchDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBVectorStoreTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientGreenNodeHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsRetrieversSelf-querying retrieversChromaOn this pageChroma\\n\\nChroma is a vector database for building AI applications with embeddings.\\n\\nIn the notebook, we\\'ll demo the SelfQueryRetriever wrapped around a Chroma vector store.\\nCreating a Chroma vector store\\u200b\\nFirst we\\'ll want to create a Chroma vector store and seed it with some data. We\\'ve created a small demo set of documents that contain summaries of movies.\\nNote: The self-query retriever requires you to have lark installed (pip install lark). We also need the langchain-chroma package.\\n%pip install --upgrade --quiet  lark\\n%pip install --upgrade --quiet  langchain-chroma\\nWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.\\nimport getpassimport osif \"OPENAI_API_KEY\" not in os.environ:    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\\nOpenAI API Key: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\\nfrom langchain_chroma import Chromafrom langchain_core.documents import Documentfrom langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings()API Reference:Document | OpenAIEmbeddings\\ndocs = [    Document(        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},    ),    Document(        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},    ),    Document(        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},    ),    Document(        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},    ),    Document(        page_content=\"Toys come alive and have a blast doing so\",        metadata={\"year\": 1995, \"genre\": \"animated\"},    ),    Document(        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",        metadata={            \"year\": 1979,            \"director\": \"Andrei Tarkovsky\",            \"genre\": \"science fiction\",            \"rating\": 9.9,        },    ),]vectorstore = Chroma.from_documents(docs, embeddings)\\nUsing embedded DuckDB without persistence: data will be transient\\nCreating our self-querying retriever\\u200b\\nNow we can instantiate our retriever. To do this we\\'ll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents.\\nfrom langchain.chains.query_constructor.schema import AttributeInfofrom langchain.retrievers.self_query.base import SelfQueryRetrieverfrom langchain_openai import OpenAImetadata_field_info = [    AttributeInfo(        name=\"genre\",        description=\"The genre of the movie\",        type=\"string or list[string]\",    ),    AttributeInfo(        name=\"year\",        description=\"The year the movie was released\",        type=\"integer\",    ),    AttributeInfo(        name=\"director\",        description=\"The name of the movie director\",        type=\"string\",    ),    AttributeInfo(        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"    ),]document_content_description = \"Brief summary of a movie\"llm = OpenAI(temperature=0)retriever = SelfQueryRetriever.from_llm(    llm, vectorstore, document_content_description, metadata_field_info, verbose=True)API Reference:AttributeInfo | SelfQueryRetriever | OpenAI\\nTesting it out\\u200b\\nAnd now we can try actually using our retriever!\\n# This example only specifies a relevant queryretriever.invoke(\"What are some movies about dinosaurs\")\\nquery=\\'dinosaur\\' filter=None\\n[Document(page_content=\\'A bunch of scientists bring back dinosaurs and mayhem breaks loose\\', metadata={\\'year\\': 1993, \\'rating\\': 7.7, \\'genre\\': \\'science fiction\\'}), Document(page_content=\\'Toys come alive and have a blast doing so\\', metadata={\\'year\\': 1995, \\'genre\\': \\'animated\\'}), Document(page_content=\\'A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\\', metadata={\\'year\\': 2006, \\'director\\': \\'Satoshi Kon\\', \\'rating\\': 8.6}), Document(page_content=\\'Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\\', metadata={\\'year\\': 2010, \\'director\\': \\'Christopher Nolan\\', \\'rating\\': 8.2})]\\n# This example only specifies a filterretriever.invoke(\"I want to watch a movie rated higher than 8.5\")\\nquery=\\' \\' filter=Comparison(comparator=<Comparator.GT: \\'gt\\'>, attribute=\\'rating\\', value=8.5)\\n[Document(page_content=\\'A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\\', metadata={\\'year\\': 2006, \\'director\\': \\'Satoshi Kon\\', \\'rating\\': 8.6}), Document(page_content=\\'Three men walk into the Zone, three men walk out of the Zone\\', metadata={\\'year\\': 1979, \\'rating\\': 9.9, \\'director\\': \\'Andrei Tarkovsky\\', \\'genre\\': \\'science fiction\\'})]\\n# This example specifies a query and a filterretriever.invoke(\"Has Greta Gerwig directed any movies about women\")\\nquery=\\'women\\' filter=Comparison(comparator=<Comparator.EQ: \\'eq\\'>, attribute=\\'director\\', value=\\'Greta Gerwig\\')\\n[Document(page_content=\\'A bunch of normal-sized women are supremely wholesome and some men pine after them\\', metadata={\\'year\\': 2019, \\'director\\': \\'Greta Gerwig\\', \\'rating\\': 8.3})]\\n# This example specifies a composite filterretriever.invoke(\"What\\'s a highly rated (above 8.5) science fiction film?\")\\nquery=\\' \\' filter=Operation(operator=<Operator.AND: \\'and\\'>, arguments=[Comparison(comparator=<Comparator.EQ: \\'eq\\'>, attribute=\\'genre\\', value=\\'science fiction\\'), Comparison(comparator=<Comparator.GT: \\'gt\\'>, attribute=\\'rating\\', value=8.5)])\\n[Document(page_content=\\'Three men walk into the Zone, three men walk out of the Zone\\', metadata={\\'year\\': 1979, \\'rating\\': 9.9, \\'director\\': \\'Andrei Tarkovsky\\', \\'genre\\': \\'science fiction\\'})]\\n# This example specifies a query and composite filterretriever.invoke(    \"What\\'s a movie after 1990 but before 2005 that\\'s all about toys, and preferably is animated\")\\nquery=\\'toys\\' filter=Operation(operator=<Operator.AND: \\'and\\'>, arguments=[Comparison(comparator=<Comparator.GT: \\'gt\\'>, attribute=\\'year\\', value=1990), Comparison(comparator=<Comparator.LT: \\'lt\\'>, attribute=\\'year\\', value=2005), Comparison(comparator=<Comparator.EQ: \\'eq\\'>, attribute=\\'genre\\', value=\\'animated\\')])\\n[Document(page_content=\\'Toys come alive and have a blast doing so\\', metadata={\\'year\\': 1995, \\'genre\\': \\'animated\\'})]\\nFilter k\\u200b\\nWe can also use the self query retriever to specify k: the number of documents to fetch.\\nWe can do this by passing enable_limit=True to the constructor.\\nretriever = SelfQueryRetriever.from_llm(    llm,    vectorstore,    document_content_description,    metadata_field_info,    enable_limit=True,    verbose=True,)\\n# This example only specifies a relevant queryretriever.invoke(\"what are two movies about dinosaurs\")\\nquery=\\'dinosaur\\' filter=None\\n[Document(page_content=\\'A bunch of scientists bring back dinosaurs and mayhem breaks loose\\', metadata={\\'year\\': 1993, \\'rating\\': 7.7, \\'genre\\': \\'science fiction\\'}), Document(page_content=\\'Toys come alive and have a blast doing so\\', metadata={\\'year\\': 1995, \\'genre\\': \\'animated\\'}), Document(page_content=\\'A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\\', metadata={\\'year\\': 2006, \\'director\\': \\'Satoshi Kon\\', \\'rating\\': 8.6}), Document(page_content=\\'Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\\', metadata={\\'year\\': 2010, \\'director\\': \\'Christopher Nolan\\', \\'rating\\': 8.2})]Edit this pagePreviousAstra DBNextDashVectorCreating a Chroma vector storeCreating our self-querying retrieverTesting it outFilter kCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nVector stores | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGreenNodeGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)SurrealDBNebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTensorlakeTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksIBM Db2 Vector Store and Vector SearchDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBVectorStoreTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientGreenNodeHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsVector storesOn this pageVector stores\\n\\nA vector store stores embedded data and performs similarity search.\\nSelect embedding model:\\n\\nSelect embeddings model:OpenAI\u25beOpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get(\"OPENAI_API_KEY\"):  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\\nSelect vector store:\\n\\nSelect vector store:In-memory\u25beIn-memoryAstraDBChromaFAISSMilvusMongoDBPGVectorPineconeQdrantpip install -qU langchain-corefrom langchain_core.vectorstores import InMemoryVectorStorevector_store = InMemoryVectorStore(embeddings)\\nVectorstoreDelete by IDFilteringSearch by VectorSearch with scoreAsyncPasses Standard TestsMulti TenancyIDs in add DocumentsAstraDBVectorStore\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705Chroma\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705Clickhouse\u2705\u2705\u274c\u2705\u274c\u274c\u274c\u2705CouchbaseSearchVectorStore\u2705\u2705\u2705\u2705\u2705\u274c\u2705\u2705DatabricksVectorSearch\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705ElasticsearchStore\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705FAISS\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705InMemoryVectorStore\u2705\u2705\u274c\u2705\u2705\u274c\u274c\u2705Milvus\u2705\u2705\u2705\u2705\u2705\u2705\u2705\u2705MongoDBAtlasVectorSearch\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705openGauss\u2705\u2705\u2705\u2705\u274c\u2705\u274c\u2705PGVector\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705PineconeVectorStore\u2705\u2705\u2705\u274c\u2705\u274c\u274c\u2705QdrantVectorStore\u2705\u2705\u2705\u2705\u2705\u274c\u2705\u2705Redis\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u2705Weaviate\u2705\u2705\u2705\u2705\u2705\u274c\u2705\u2705SQLServer\u2705\u2705\u2705\u2705\u274c\u274c\u274c\u2705\\nAll Vectorstores\\u200b\\nNameDescriptionActiveloop Deep LakeActiveloop Deep Lake as a Multi-Modal Vector Store that stores embedd...AerospikeAerospike Vector Search (AVS) is anAlibaba Cloud OpenSearchAlibaba Cloud Opensearch is a one-stop platform to develop intelligen...AnalyticDBAnalyticDB for PostgreSQL is a massively parallel processing (MPP) da...AnnoyAnnoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with P...Apache DorisApache Doris is a modern data warehouse for real-time analytics.ApertureDBApertureDB is a database that stores, indexes, and manages multi-moda...Astra DB Vector StoreThis page provides a quickstart for using Astra DB as a Vector Store.AtlasAtlas is a platform by Nomic made for interacting with both small and...AwaDBAwaDB is an AI Native database for the search and storage of embeddin...Azure Cosmos DB Mongo vCoreThis notebook shows you how to leverage this integrated vector databa...Azure Cosmos DB No SQLThis notebook shows you how to leverage this integrated vector databa...Azure AI SearchAzure AI Search (formerly known as Azure Search and Azure Cognitive S...BagelBagel (Open Inference platform for AI), is like GitHub for AI data.BagelDBBagelDB (Open Vector Database for AI), is like GitHub for AI data.Baidu Cloud ElasticSearch VectorSearchBaidu Cloud VectorSearch is a fully managed, enterprise-level distrib...Baidu VectorDBBaidu VectorDB is a robust, enterprise-level distributed database ser...Apache CassandraThis page provides a quickstart for using Apache Cassandra\u00ae as a Vect...ChromaThis notebook covers how to get started with the Chroma vector store.ClarifaiClarifai is an AI Platform that provides the full AI lifecycle rangin...ClickHouseClickHouse is the fastest and most resource efficient open-source dat...CloudflareVectorizeThis notebook covers how to get started with the CloudflareVectorize ...CouchbaseCouchbase is an award-winning distributed NoSQL cloud database that d...DashVectorDashVector is a fully-managed vectorDB service that supports high-dim...DatabricksDatabricks Vector Search is a serverless similarity search engine tha...IBM Db2 Vector Store and Vector SearchLangChain\\'s Db2 integration (langchain-db2) provides vector store and...DingoDBDingoDB is a distributed multi-mode vector database, which combines t...DocArray HnswSearchDocArrayHnswSearch is a lightweight Document Index implementation pro...DocArray InMemorySearchDocArrayInMemorySearch is a document index provided by Docarray that ...Amazon Document DBAmazon DocumentDB (with MongoDB Compatibility) makes it easy to set u...DuckDBThis notebook shows how to use DuckDB as a vector store.China Mobile ECloud ElasticSearch VectorSearchChina Mobile ECloud VectorSearch is a fully managed, enterprise-level...ElasticsearchElasticsearch is a distributed, RESTful search and analytics engine, ...EpsillaEpsilla is an open-source vector database that leverages the advanced...FaissFacebook AI Similarity Search (FAISS) is a library for efficient simi...Faiss (Async)Facebook AI Similarity Search (Faiss) is a library for efficient simi...FalkorDBVectorStoreFalkorDB is an open-source graph database with integrated support for...GelAn implementation of LangChain vectorstore abstraction using gel as t...Google AlloyDB for PostgreSQLAlloyDB is a fully managed relational database service that offers hi...Google BigQuery Vector SearchGoogle Cloud BigQuery Vector Search lets you use GoogleSQL to do sema...Google Cloud SQL for MySQLCloud SQL is a fully managed relational database service that offers ...Google Cloud SQL for PostgreSQLCloud SQL is a fully managed relational database service that offers ...FirestoreFirestore is a serverless document-oriented database that scales to m...Google Memorystore for RedisGoogle Memorystore for Redis is a fully-managed service that is power...Google SpannerSpanner is a highly scalable database that combines unlimited scalabi...Google Vertex AI Feature StoreGoogle Cloud Vertex Feature Store streamlines your ML feature managem...Google Vertex AI Vector SearchThis notebook shows how to use functionality related to the Google Cl...HippoTranswarp Hippo is an enterprise-level cloud-native distributed vecto...HologresHologres is a unified real-time data warehousing service developed by...InfinispanInfinispan is an open-source key-value data grid, it can work as sing...Jaguar Vector Database1. It is a distributed vector databaseKDB.AIKDB.AI is a powerful knowledge-based vector database and search engin...KineticaKinetica is a database with integrated support for vector similarity ...LanceDBLanceDB is an open-source database for vector-search built with persi...LanternLantern is an open-source vector similarity search for PostgresLindormThis notebook covers how to get started with the Lindorm vector store.LLMRailsLLMRails is a API platform for building GenAI applications. It provid...ManticoreSearch VectorStoreManticoreSearch is an open-source search engine that offers fast, sca...MariaDBLangChain\\'s MariaDB integration (langchain-mariadb) provides vector c...MarqoThis notebook shows how to use functionality related to the Marqo vec...MeilisearchMeilisearch is an open-source, lightning-fast, and hyper relevant sea...Amazon MemoryDBVector Search introduction and langchain integration guide.MilvusMilvus is a database that stores, indexes, and manages massive embedd...Momento Vector Index (MVI)MVI: the most productive, easiest to use, serverless vector index for...MongoDB AtlasThis notebook covers how to MongoDB Atlas vector search in LangChain,...MyScaleMyScale is a cloud-based database optimized for AI applications and s...Neo4j Vector IndexNeo4j is an open-source graph database with integrated support for ve...NucliaDBYou can use a local NucliaDB instance or use Nuclia Cloud.OceanbaseThis notebook covers how to get started with the Oceanbase vector sto...openGaussThis notebook covers how to get started with the openGauss VectorStor...OpenSearchOpenSearch is a scalable, flexible, and extensible open-source softwa...Oracle AI Vector Search: Vector StoreOracle AI Vector Search is designed for Artificial Intelligence (AI) ...PathwayPathway is an open data processing framework. It allows you to easily...Postgres EmbeddingPostgres Embedding is an open-source vector similarity search for Pos...PGVecto.rsThis notebook shows how to use functionality related to the Postgres ...PGVectorAn implementation of LangChain vectorstore abstraction using postgres...PineconePinecone is a vector database with broad functionality.Pinecone (sparse)Pinecone is a vector database with broad functionality.QdrantQdrant (read: quadrant) is a vector similarity search engine. It prov...RedisThis notebook covers how to get started with the Redis vector store.RelytRelyt is a cloud native data warehousing service that is designed to ...RocksetRockset is a real-time search and analytics database built for the cl...SAP HANA Cloud Vector EngineSAP HANA Cloud Vector Engine is a vector store fully integrated into ...ScaNNScaNN (Scalable Nearest Neighbors) is a method for efficient vector s...SemaDBSemaDB from SemaFind is a no fuss vector similarity database for buil...SingleStoreSingleStore is a robust, high-performance distributed SQL database so...scikit-learnscikit-learn is an open-source collection of machine learning algorit...SQLiteVecThis notebook covers how to get started with the SQLiteVec vector sto...SQLite-VSSSQLite-VSS is an SQLite extension designed for vector search, emphasi...SQLServerAzure SQL provides a dedicated\\xa0Vector data type that simplifies the c...StarRocksStarRocks is a High-Performance Analytical Database.Supabase (Postgres)Supabase is an open-source Firebase alternative. Supabase is built on...SurrealDBVectorStoreSurrealDB is a unified, multi-model database purpose-built for AI sys...TablestoreTablestore is a fully managed NoSQL cloud database service.TairTair is a cloud native in-memory database service developed by Alibab...Tencent Cloud VectorDBTencent Cloud VectorDB is a fully managed, self-developed, enterprise...ThirdAI NeuralDBNeuralDB is a CPU-friendly and fine-tunable vector store developed by...TiDB VectorTiDB Cloud, is a comprehensive Database-as-a-Service (DBaaS) solution...TigrisTigris is an open-source Serverless NoSQL Database and Search Platfor...TileDBTileDB is a powerful engine for indexing and querying dense and spars...Timescale Vector (Postgres)Timescale Vector is PostgreSQL++ vector database for AI applications.TypesenseTypesense is an open-source, in-memory search engine, that you can ei...Upstash VectorUpstash Vector is a serverless vector database designed for working w...USearchUSearch is a Smaller & Faster Single-File Vector Search EngineValdVald is a highly scalable distributed fast approximate nearest neighb...VDMSThis notebook covers how to get started with VDMS as a vector store.VearchVearch is the vector search infrastructure for deeping learning and A...VectaraVectara is the trusted AI Assistant and Agent platform which focuses ...VespaVespa is a fully featured search engine and vector database. It suppo...viking DBviking DB is a database that stores, indexes, and manages massive emb...vliteVLite is a simple and blazing fast vector database that allows you to...WeaviateThis notebook covers how to get started with the Weaviate vector stor...XataXata is a serverless data platform, based on PostgreSQL. It provides ...YDBYDB is a versatile open source Distributed SQL Database that combines...YellowbrickYellowbrick is an elastic, massively parallel processing (MPP) SQL da...ZepRecall, understand, and extract data from chat histories. Power perso...Zep CloudRecall, understand, and extract data from chat histories. Power perso...ZillizZilliz Cloud is a fully managed service on cloud for LF AI Milvus\u00ae,Edit this pagePreviousZeroxPDFLoaderNextVector storesAll VectorstoresCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nChroma | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGreenNodeGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)SurrealDBNebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTensorlakeTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksIBM Db2 Vector Store and Vector SearchDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBVectorStoreTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientGreenNodeHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherProvidersMoreChromaOn this pageChroma\\n\\nChroma is a database for building AI applications with embeddings.\\n\\nInstallation and Setup\\u200b\\npip install langchain-chroma\\nVectorStore\\u200b\\nThere exists a wrapper around Chroma vector databases, allowing you to use it as a vectorstore,\\nwhether for semantic search or example selection.\\nfrom langchain_chroma import Chroma\\nFor a more detailed walkthrough of the Chroma wrapper, see this notebook\\nRetriever\\u200b\\nSee a usage example.\\nfrom langchain.retrievers import SelfQueryRetrieverAPI Reference:SelfQueryRetrieverEdit this pagePreviousChaindeskNextClarifaiInstallation and SetupVectorStoreRetrieverCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nHow to retrieve using multiple vectors per document | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to retrieve using multiple vectors per documentOn this pageHow to retrieve using multiple vectors per document\\nIt can often be useful to store multiple vectors per document. There are multiple use cases where this is beneficial. For example, we can embed multiple chunks of a document and associate those embeddings with the parent document, allowing retriever hits on the chunks to return the larger document.\\nLangChain implements a base MultiVectorRetriever, which simplifies this process. Much of the complexity lies in how to create the multiple vectors per document. This notebook covers some of the common ways to create those vectors and use the MultiVectorRetriever.\\nThe methods to create multiple vectors per document include:\\n\\nSmaller chunks: split a document into smaller chunks, and embed those (this is ParentDocumentRetriever).\\nSummary: create a summary for each document, embed that along with (or instead of) the document.\\nHypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.\\n\\nNote that this also enables another method of adding embeddings - manually. This is useful because you can explicitly add questions or queries that should lead to a document being recovered, giving you more control.\\nBelow we walk through an example. First we instantiate some documents. We will index them in an (in-memory) Chroma vector store using OpenAI embeddings, but any LangChain vector store or embeddings model will suffice.\\n%pip install --upgrade --quiet  langchain-chroma langchain langchain-openai > /dev/null\\nfrom langchain.storage import InMemoryByteStorefrom langchain_chroma import Chromafrom langchain_community.document_loaders import TextLoaderfrom langchain_openai import OpenAIEmbeddingsfrom langchain_text_splitters import RecursiveCharacterTextSplitterloaders = [    TextLoader(\"paul_graham_essay.txt\"),    TextLoader(\"state_of_the_union.txt\"),]docs = []for loader in loaders:    docs.extend(loader.load())text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)docs = text_splitter.split_documents(docs)# The vectorstore to use to index the child chunksvectorstore = Chroma(    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings())API Reference:InMemoryByteStore | TextLoader | OpenAIEmbeddings | RecursiveCharacterTextSplitter\\nSmaller chunks\\u200b\\nOften times it can be useful to retrieve larger chunks of information, but embed smaller chunks. This allows for embeddings to capture the semantic meaning as closely as possible, but for as much context as possible to be passed downstream. Note that this is what the ParentDocumentRetriever does. Here we show what is going on under the hood.\\nWe will make a distinction between the vector store, which indexes embeddings of the (sub) documents, and the document store, which houses the \"parent\" documents and associates them with an identifier.\\nimport uuidfrom langchain.retrievers.multi_vector import MultiVectorRetriever# The storage layer for the parent documentsstore = InMemoryByteStore()id_key = \"doc_id\"# The retriever (empty to start)retriever = MultiVectorRetriever(    vectorstore=vectorstore,    byte_store=store,    id_key=id_key,)doc_ids = [str(uuid.uuid4()) for _ in docs]API Reference:MultiVectorRetriever\\nWe next generate the \"sub\" documents by splitting the original documents. Note that we store the document identifier in the metadata of the corresponding Document object.\\n# The splitter to use to create smaller chunkschild_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)sub_docs = []for i, doc in enumerate(docs):    _id = doc_ids[i]    _sub_docs = child_text_splitter.split_documents([doc])    for _doc in _sub_docs:        _doc.metadata[id_key] = _id    sub_docs.extend(_sub_docs)\\nFinally, we index the documents in our vector store and document store:\\nretriever.vectorstore.add_documents(sub_docs)retriever.docstore.mset(list(zip(doc_ids, docs)))\\nThe vector store alone will retrieve small chunks:\\nretriever.vectorstore.similarity_search(\"justice breyer\")[0]\\nDocument(page_content=\\'Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\\\n\\\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\\', metadata={\\'doc_id\\': \\'064eca46-a4c4-4789-8e3b-583f9597e54f\\', \\'source\\': \\'state_of_the_union.txt\\'})\\nWhereas the retriever will return the larger parent document:\\nlen(retriever.invoke(\"justice breyer\")[0].page_content)\\n9875\\nThe default search type the retriever performs on the vector database is a similarity search. LangChain vector stores also support searching via Max Marginal Relevance. This can be controlled via the search_type parameter of the retriever:\\nfrom langchain.retrievers.multi_vector import SearchTyperetriever.search_type = SearchType.mmrlen(retriever.invoke(\"justice breyer\")[0].page_content)API Reference:SearchType\\n9875\\nAssociating summaries with a document for retrieval\\u200b\\nA summary may be able to distill more accurately what a chunk is about, leading to better retrieval. Here we show how to create summaries, and then embed those.\\nWe construct a simple chain that will receive an input Document object and generate a summary using a LLM.\\n\\nSelect chat model:Google Gemini\u25beOpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelllm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\\nimport uuidfrom langchain_core.documents import Documentfrom langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatechain = (    {\"doc\": lambda x: x.page_content}    | ChatPromptTemplate.from_template(\"Summarize the following document:\\\\n\\\\n{doc}\")    | llm    | StrOutputParser())API Reference:Document | StrOutputParser | ChatPromptTemplate\\nNote that we can batch the chain across documents:\\nsummaries = chain.batch(docs, {\"max_concurrency\": 5})\\nWe can then initialize a MultiVectorRetriever as before, indexing the summaries in our vector store, and retaining the original documents in our document store:\\n# The vectorstore to use to index the child chunksvectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())# The storage layer for the parent documentsstore = InMemoryByteStore()id_key = \"doc_id\"# The retriever (empty to start)retriever = MultiVectorRetriever(    vectorstore=vectorstore,    byte_store=store,    id_key=id_key,)doc_ids = [str(uuid.uuid4()) for _ in docs]summary_docs = [    Document(page_content=s, metadata={id_key: doc_ids[i]})    for i, s in enumerate(summaries)]retriever.vectorstore.add_documents(summary_docs)retriever.docstore.mset(list(zip(doc_ids, docs)))\\n# # We can also add the original chunks to the vectorstore if we so want# for i, doc in enumerate(docs):#     doc.metadata[id_key] = doc_ids[i]# retriever.vectorstore.add_documents(docs)\\nQuerying the vector store will return summaries:\\nsub_docs = retriever.vectorstore.similarity_search(\"justice breyer\")sub_docs[0]\\nDocument(page_content=\"President Biden recently nominated Judge Ketanji Brown Jackson to serve on the United States Supreme Court, emphasizing her qualifications and broad support. The President also outlined a plan to secure the border, fix the immigration system, protect women\\'s rights, support LGBTQ+ Americans, and advance mental health services. He highlighted the importance of bipartisan unity in passing legislation, such as the Violence Against Women Act. The President also addressed supporting veterans, particularly those impacted by exposure to burn pits, and announced plans to expand benefits for veterans with respiratory cancers. Additionally, he proposed a plan to end cancer as we know it through the Cancer Moonshot initiative. President Biden expressed optimism about the future of America and emphasized the strength of the American people in overcoming challenges.\", metadata={\\'doc_id\\': \\'84015b1b-980e-400a-94d8-cf95d7e079bd\\'})\\nWhereas the retriever will return the larger source document:\\nretrieved_docs = retriever.invoke(\"justice breyer\")len(retrieved_docs[0].page_content)\\n9194\\nHypothetical Queries\\u200b\\nAn LLM can also be used to generate a list of hypothetical questions that could be asked of a particular document, which might bear close semantic similarity to relevant queries in a RAG application. These questions can then be embedded and associated with the documents to improve retrieval.\\nBelow, we use the with_structured_output method to structure the LLM output into a list of strings.\\nfrom typing import Listfrom pydantic import BaseModel, Fieldclass HypotheticalQuestions(BaseModel):    \"\"\"Generate hypothetical questions.\"\"\"    questions: List[str] = Field(..., description=\"List of questions\")chain = (    {\"doc\": lambda x: x.page_content}    # Only asking for 3 hypothetical questions, but this could be adjusted    | ChatPromptTemplate.from_template(        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer:\\\\n\\\\n{doc}\"    )    | ChatOpenAI(max_retries=0, model=\"gpt-4o\").with_structured_output(        HypotheticalQuestions    )    | (lambda x: x.questions))\\nInvoking the chain on a single document demonstrates that it outputs a list of questions:\\nchain.invoke(docs[0])\\n[\"What impact did the IBM 1401 have on the author\\'s early programming experiences?\", \"How did the transition from using the IBM 1401 to microcomputers influence the author\\'s programming journey?\", \"What role did Lisp play in shaping the author\\'s understanding and approach to AI?\"]\\nWe can batch then batch the chain over all documents and assemble our vector store and document store as before:\\n# Batch chain over documents to generate hypothetical questionshypothetical_questions = chain.batch(docs, {\"max_concurrency\": 5})# The vectorstore to use to index the child chunksvectorstore = Chroma(    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings())# The storage layer for the parent documentsstore = InMemoryByteStore()id_key = \"doc_id\"# The retriever (empty to start)retriever = MultiVectorRetriever(    vectorstore=vectorstore,    byte_store=store,    id_key=id_key,)doc_ids = [str(uuid.uuid4()) for _ in docs]# Generate Document objects from hypothetical questionsquestion_docs = []for i, question_list in enumerate(hypothetical_questions):    question_docs.extend(        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]    )retriever.vectorstore.add_documents(question_docs)retriever.docstore.mset(list(zip(doc_ids, docs)))\\nNote that querying the underlying vector store will retrieve hypothetical questions that are semantically similar to the input query:\\nsub_docs = retriever.vectorstore.similarity_search(\"justice breyer\")sub_docs\\n[Document(page_content=\\'What might be the potential benefits of nominating Circuit Court of Appeals Judge Ketanji Brown Jackson to the United States Supreme Court?\\', metadata={\\'doc_id\\': \\'43292b74-d1b8-4200-8a8b-ea0cb57fbcdb\\'}), Document(page_content=\\'How might the Bipartisan Infrastructure Law impact the economic competition between the U.S. and China?\\', metadata={\\'doc_id\\': \\'66174780-d00c-4166-9791-f0069846e734\\'}), Document(page_content=\\'What factors led to the creation of Y Combinator?\\', metadata={\\'doc_id\\': \\'72003c4e-4cc9-4f09-a787-0b541a65b38c\\'}), Document(page_content=\\'How did the ability to publish essays online change the landscape for writers and thinkers?\\', metadata={\\'doc_id\\': \\'e8d2c648-f245-4bcc-b8d3-14e64a164b64\\'})]\\nAnd invoking the retriever will return the corresponding document:\\nretrieved_docs = retriever.invoke(\"justice breyer\")len(retrieved_docs[0].page_content)\\n9194Edit this pagePreviousHow to migrate from legacy LangChain agents to LangGraphNextHow to pass multimodal data to modelsSmaller chunksAssociating summaries with a document for retrievalHypothetical QueriesCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nHow to use the LangChain indexing API | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to use the LangChain indexing APIOn this pageHow to use the LangChain indexing API\\nHere, we will look at a basic indexing workflow using the LangChain indexing API.\\nThe indexing API lets you load and keep in sync documents from any source into a vector store. Specifically, it helps:\\n\\nAvoid writing duplicated content into the vector store\\nAvoid re-writing unchanged content\\nAvoid re-computing embeddings over unchanged content\\n\\nAll of which should save you time and money, as well as improve your vector search results.\\nCrucially, the indexing API will work even with documents that have gone through several\\ntransformation steps (e.g., via text chunking) with respect to the original source documents.\\nHow it works\\u200b\\nLangChain indexing makes use of a record manager (RecordManager) that keeps track of document writes into the vector store.\\nWhen indexing content, hashes are computed for each document, and the following information is stored in the record manager:\\n\\nthe document hash (hash of both page content and metadata)\\nwrite time\\nthe source id -- each document should include information in its metadata to allow us to determine the ultimate source of this document\\n\\nDeletion modes\\u200b\\nWhen indexing documents into a vector store, it\\'s possible that some existing documents in the vector store should be deleted. In certain situations you may want to remove any existing documents that are derived from the same sources as the new documents being indexed. In others you may want to delete all existing documents wholesale. The indexing API deletion modes let you pick the behavior you want:\\nCleanup ModeDe-Duplicates ContentParallelizableCleans Up Deleted Source DocsCleans Up Mutations of Source Docs and/or Derived DocsClean Up TimingNone\u2705\u2705\u274c\u274c-Incremental\u2705\u2705\u274c\u2705ContinuouslyFull\u2705\u274c\u2705\u2705At end of indexingScoped_Full\u2705\u2705\u274c\u2705At end of indexing\\nNone does not do any automatic clean up, allowing the user to manually do clean up of old content.\\nincremental, full and scoped_full offer the following automated clean up:\\n\\nIf the content of the source document or derived documents has changed, all 3 modes will clean up (delete) previous versions of the content.\\nIf the source document has been deleted (meaning it is not included in the documents currently being indexed), the full cleanup mode will delete it from the vector store correctly, but the incremental and scoped_full mode will not.\\n\\nWhen content is mutated (e.g., the source PDF file was revised) there will be a period of time during indexing when both the new and old versions may be returned to the user. This happens after the new content was written, but before the old version was deleted.\\n\\nincremental indexing minimizes this period of time as it is able to do clean up continuously, as it writes.\\nfull and scoped_full mode does the clean up after all batches have been written.\\n\\nRequirements\\u200b\\n\\nDo not use with a store that has been pre-populated with content independently of the indexing API, as the record manager will not know that records have been inserted previously.\\nOnly works with LangChain vectorstore\\'s that support:\\n\\ndocument addition by id (add_documents method with ids argument)\\ndelete by id (delete method with ids argument)\\n\\n\\n\\nCompatible Vectorstores: Aerospike, AnalyticDB, AstraDB, AwaDB, AzureCosmosDBNoSqlVectorSearch, AzureCosmosDBVectorSearch, AzureSearch, Bagel, Cassandra, Chroma, CouchbaseVectorStore, DashVector, DatabricksVectorSearch, DeepLake, Dingo, ElasticVectorSearch, ElasticsearchStore, FAISS, HanaDB, Milvus, MongoDBAtlasVectorSearch, MyScale, OpenSearchVectorSearch, PGVector, Pinecone, Qdrant, Redis, Rockset, ScaNN, SingleStoreDB, SupabaseVectorStore, SurrealDBStore, TimescaleVector, Vald, VDMS, Vearch, VespaStore, Weaviate, Yellowbrick, ZepVectorStore, TencentVectorDB, OpenSearchVectorSearch.\\nCaution\\u200b\\nThe record manager relies on a time-based mechanism to determine what content can be cleaned up (when using full or incremental or scoped_full cleanup modes).\\nIf two tasks run back-to-back, and the first task finishes before the clock time changes, then the second task may not be able to clean up content.\\nThis is unlikely to be an issue in actual settings for the following reasons:\\n\\nThe RecordManager uses higher resolution timestamps.\\nThe data would need to change between the first and the second tasks runs, which becomes unlikely if the time interval between the tasks is small.\\nIndexing tasks typically take more than a few ms.\\n\\nQuickstart\\u200b\\nfrom langchain.indexes import SQLRecordManager, indexfrom langchain_core.documents import Documentfrom langchain_elasticsearch import ElasticsearchStorefrom langchain_openai import OpenAIEmbeddingsAPI Reference:SQLRecordManager | index | Document | ElasticsearchStore | OpenAIEmbeddings\\nInitialize a vector store and set up the embeddings:\\ncollection_name = \"test_index\"embedding = OpenAIEmbeddings()vectorstore = ElasticsearchStore(    es_url=\"http://localhost:9200\", index_name=\"test_index\", embedding=embedding)\\nInitialize a record manager with an appropriate namespace.\\nSuggestion: Use a namespace that takes into account both the vector store and the collection name in the vector store; e.g., \\'redis/my_docs\\', \\'chromadb/my_docs\\' or \\'postgres/my_docs\\'.\\nnamespace = f\"elasticsearch/{collection_name}\"record_manager = SQLRecordManager(    namespace, db_url=\"sqlite:///record_manager_cache.sql\")\\nCreate a schema before using the record manager.\\nrecord_manager.create_schema()\\nLet\\'s index some test documents:\\ndoc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})\\nIndexing into an empty vector store:\\ndef _clear():    \"\"\"Hacky helper method to clear content. See the `full` mode section to to understand why it works.\"\"\"    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\\nNone deletion mode\\u200b\\nThis mode does not do automatic clean up of old versions of content; however, it still takes care of content de-duplication.\\n_clear()\\nindex(    [doc1, doc1, doc1, doc1, doc1],    record_manager,    vectorstore,    cleanup=None,    source_id_key=\"source\",)\\n{\\'num_added\\': 1, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 0}\\n_clear()\\nindex([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")\\n{\\'num_added\\': 2, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 0}\\nSecond time around all content will be skipped:\\nindex([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")\\n{\\'num_added\\': 0, \\'num_updated\\': 0, \\'num_skipped\\': 2, \\'num_deleted\\': 0}\\n\"incremental\" deletion mode\\u200b\\n_clear()\\nindex(    [doc1, doc2],    record_manager,    vectorstore,    cleanup=\"incremental\",    source_id_key=\"source\",)\\n{\\'num_added\\': 2, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 0}\\nIndexing again should result in both documents getting skipped -- also skipping the embedding operation!\\nindex(    [doc1, doc2],    record_manager,    vectorstore,    cleanup=\"incremental\",    source_id_key=\"source\",)\\n{\\'num_added\\': 0, \\'num_updated\\': 0, \\'num_skipped\\': 2, \\'num_deleted\\': 0}\\nIf we provide no documents with incremental indexing mode, nothing will change.\\nindex([], record_manager, vectorstore, cleanup=\"incremental\", source_id_key=\"source\")\\n{\\'num_added\\': 0, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 0}\\nIf we mutate a document, the new version will be written and all old versions sharing the same source will be deleted.\\nchanged_doc_2 = Document(page_content=\"puppy\", metadata={\"source\": \"doggy.txt\"})\\nindex(    [changed_doc_2],    record_manager,    vectorstore,    cleanup=\"incremental\",    source_id_key=\"source\",)\\n{\\'num_added\\': 1, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 1}\\n\"full\" deletion mode\\u200b\\nIn full mode the user should pass the full universe of content that should be indexed into the indexing function.\\nAny documents that are not passed into the indexing function and are present in the vectorstore will be deleted!\\nThis behavior is useful to handle deletions of source documents.\\n_clear()\\nall_docs = [doc1, doc2]\\nindex(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\\n{\\'num_added\\': 2, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 0}\\nSay someone deleted the first doc:\\ndel all_docs[0]\\nall_docs\\n[Document(page_content=\\'doggy\\', metadata={\\'source\\': \\'doggy.txt\\'})]\\nUsing full mode will clean up the deleted content as well.\\nindex(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\\n{\\'num_added\\': 0, \\'num_updated\\': 0, \\'num_skipped\\': 1, \\'num_deleted\\': 1}\\nSource\\u200b\\nThe metadata attribute contains a field called source. This source should be pointing at the ultimate provenance associated with the given document.\\nFor example, if these documents are representing chunks of some parent document, the source for both documents should be the same and reference the parent document.\\nIn general, source should always be specified. Only use a None, if you never intend to use incremental mode, and for some reason can\\'t specify the source field correctly.\\nfrom langchain_text_splitters import CharacterTextSplitterAPI Reference:CharacterTextSplitter\\ndoc1 = Document(    page_content=\"kitty kitty kitty kitty kitty\", metadata={\"source\": \"kitty.txt\"})doc2 = Document(page_content=\"doggy doggy the doggy\", metadata={\"source\": \"doggy.txt\"})\\nnew_docs = CharacterTextSplitter(    separator=\"t\", keep_separator=True, chunk_size=12, chunk_overlap=2).split_documents([doc1, doc2])new_docs\\n[Document(page_content=\\'kitty kit\\', metadata={\\'source\\': \\'kitty.txt\\'}), Document(page_content=\\'tty kitty ki\\', metadata={\\'source\\': \\'kitty.txt\\'}), Document(page_content=\\'tty kitty\\', metadata={\\'source\\': \\'kitty.txt\\'}), Document(page_content=\\'doggy doggy\\', metadata={\\'source\\': \\'doggy.txt\\'}), Document(page_content=\\'the doggy\\', metadata={\\'source\\': \\'doggy.txt\\'})]\\n_clear()\\nindex(    new_docs,    record_manager,    vectorstore,    cleanup=\"incremental\",    source_id_key=\"source\",)\\n{\\'num_added\\': 5, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 0}\\nchanged_doggy_docs = [    Document(page_content=\"woof woof\", metadata={\"source\": \"doggy.txt\"}),    Document(page_content=\"woof woof woof\", metadata={\"source\": \"doggy.txt\"}),]\\nThis should delete the old versions of documents associated with doggy.txt source and replace them with the new versions.\\nindex(    changed_doggy_docs,    record_manager,    vectorstore,    cleanup=\"incremental\",    source_id_key=\"source\",)\\n{\\'num_added\\': 2, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 2}\\nvectorstore.similarity_search(\"dog\", k=30)\\n[Document(page_content=\\'woof woof\\', metadata={\\'source\\': \\'doggy.txt\\'}), Document(page_content=\\'woof woof woof\\', metadata={\\'source\\': \\'doggy.txt\\'}), Document(page_content=\\'tty kitty\\', metadata={\\'source\\': \\'kitty.txt\\'}), Document(page_content=\\'tty kitty ki\\', metadata={\\'source\\': \\'kitty.txt\\'}), Document(page_content=\\'kitty kit\\', metadata={\\'source\\': \\'kitty.txt\\'})]\\nUsing with loaders\\u200b\\nIndexing can accept either an iterable of documents or else any loader.\\nAttention: The loader must set source keys correctly.\\nfrom langchain_core.document_loaders import BaseLoaderclass MyCustomLoader(BaseLoader):    def lazy_load(self):        text_splitter = CharacterTextSplitter(            separator=\"t\", keep_separator=True, chunk_size=12, chunk_overlap=2        )        docs = [            Document(page_content=\"woof woof\", metadata={\"source\": \"doggy.txt\"}),            Document(page_content=\"woof woof woof\", metadata={\"source\": \"doggy.txt\"}),        ]        yield from text_splitter.split_documents(docs)    def load(self):        return list(self.lazy_load())API Reference:BaseLoader\\n_clear()\\nloader = MyCustomLoader()\\nloader.load()\\n[Document(page_content=\\'woof woof\\', metadata={\\'source\\': \\'doggy.txt\\'}), Document(page_content=\\'woof woof woof\\', metadata={\\'source\\': \\'doggy.txt\\'})]\\nindex(loader, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\\n{\\'num_added\\': 2, \\'num_updated\\': 0, \\'num_skipped\\': 0, \\'num_deleted\\': 0}\\nvectorstore.similarity_search(\"dog\", k=30)\\n[Document(page_content=\\'woof woof\\', metadata={\\'source\\': \\'doggy.txt\\'}), Document(page_content=\\'woof woof woof\\', metadata={\\'source\\': \\'doggy.txt\\'})]Edit this pagePreviousHybrid SearchNextHow to inspect runnablesHow it worksDeletion modesRequirementsCautionQuickstartNone deletion mode\"incremental\" deletion mode\"full\" deletion modeSourceUsing with loadersCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nOllamaEmbeddings | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGreenNodeGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)SurrealDBNebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTensorlakeTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksIBM Db2 Vector Store and Vector SearchDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBVectorStoreTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientGreenNodeHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsEmbedding modelsOllamaOn this pageOllamaEmbeddings\\nThis will help you get started with Ollama embedding models using LangChain. For detailed documentation on OllamaEmbeddings features and configuration options, please refer to the API reference.\\nOverview\\u200b\\nIntegration details\\u200b\\n\\nProviderPackageOllamalangchain-ollama\\nSetup\\u200b\\nFirst, follow these instructions to set up and run a local Ollama instance:\\n\\nDownload and install Ollama onto the available supported platforms (including Windows Subsystem for Linux aka WSL, macOS, and Linux)\\n\\nmacOS users can install via Homebrew with brew install ollama and start with brew services start ollama\\n\\n\\nFetch available LLM model via ollama pull <name-of-model>\\n\\nView a list of available models via the model library\\ne.g., ollama pull llama3\\n\\n\\nThis will download the default tagged version of the model. Typically, the default points to the latest, smallest sized-parameter model.\\n\\n\\nOn Mac, the models will be download to ~/.ollama/models\\nOn Linux (or WSL), the models will be stored at /usr/share/ollama/.ollama/models\\n\\n\\nSpecify the exact version of the model of interest as such ollama pull vicuna:13b-v1.5-16k-q4_0 (View the various tags for the Vicuna model in this instance)\\nTo view all pulled models, use ollama list\\nTo chat directly with a model from the command line, use ollama run <name-of-model>\\nView the Ollama documentation for more commands. You can run ollama help in the terminal to see available commands.\\n\\nTo enable automated tracing of your model calls, set your LangSmith API key:\\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\\nInstallation\\u200b\\nThe LangChain Ollama integration lives in the langchain-ollama package:\\n%pip install -qU langchain-ollama\\nNote: you may need to restart the kernel to use updated packages.\\nInstantiation\\u200b\\nNow we can instantiate our model object and generate embeddings:\\nfrom langchain_ollama import OllamaEmbeddingsembeddings = OllamaEmbeddings(    model=\"llama3\",)API Reference:OllamaEmbeddings\\nIndexing and Retrieval\\u200b\\nEmbedding models are often used in retrieval-augmented generation (RAG) flows, both as part of indexing data as well as later retrieving it. For more detailed instructions, please see our RAG tutorials.\\nBelow, see how to index and retrieve data using the embeddings object we initialized above. In this example, we will index and retrieve a sample document in the InMemoryVectorStore.\\n# Create a vector store with a sample textfrom langchain_core.vectorstores import InMemoryVectorStoretext = \"LangChain is the framework for building context-aware reasoning applications\"vectorstore = InMemoryVectorStore.from_texts(    [text],    embedding=embeddings,)# Use the vectorstore as a retrieverretriever = vectorstore.as_retriever()# Retrieve the most similar textretrieved_documents = retriever.invoke(\"What is LangChain?\")# Show the retrieved document\\'s contentprint(retrieved_documents[0].page_content)API Reference:InMemoryVectorStore\\nLangChain is the framework for building context-aware reasoning applications\\nDirect Usage\\u200b\\nUnder the hood, the vectorstore and retriever implementations are calling embeddings.embed_documents(...) and embeddings.embed_query(...) to create embeddings for the text(s) used in from_texts and retrieval invoke operations, respectively.\\nYou can directly call these methods to get embeddings for your own use cases.\\nEmbed single texts\\u200b\\nYou can embed single texts or documents with embed_query:\\nsingle_vector = embeddings.embed_query(text)print(str(single_vector)[:100])  # Show the first 100 characters of the vector\\n[-0.0039849705, 0.023019705, -0.001768838, -0.0058736936, 0.00040999008, 0.017861595, -0.011274585,\\nEmbed multiple texts\\u200b\\nYou can embed multiple texts with embed_documents:\\ntext2 = (    \"LangGraph is a library for building stateful, multi-actor applications with LLMs\")two_vectors = embeddings.embed_documents([text, text2])for vector in two_vectors:    print(str(vector)[:100])  # Show the first 100 characters of the vector\\n[-0.0039849705, 0.023019705, -0.001768838, -0.0058736936, 0.00040999008, 0.017861595, -0.011274585, [-0.0066985516, 0.009878328, 0.008019467, -0.009384944, -0.029560851, 0.025744654, 0.004872892, -0.0\\nAPI Reference\\u200b\\nFor detailed documentation on OllamaEmbeddings features and configuration options, please refer to the API reference.\\nRelated\\u200b\\n\\nEmbedding model conceptual guide\\nEmbedding model how-to guides\\nEdit this pagePreviousOracle Cloud Infrastructure Generative AINextOpenClipOverviewIntegration detailsSetupInstallationInstantiationIndexing and RetrievalDirect UsageEmbed single textsEmbed multiple textsAPI ReferenceRelatedCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nBuild a Retrieval Augmented Generation (RAG) App: Part 1 | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild a Retrieval Augmented Generation (RAG) App: Part 1On this pageBuild a Retrieval Augmented Generation (RAG) App: Part 1\\nOne of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.\\nThis is a multi-part tutorial:\\n\\nPart 1 (this guide) introduces RAG and walks through a minimal implementation.\\nPart 2 extends the implementation to accommodate conversation-style interactions and multi-step retrieval processes.\\n\\nThis tutorial will show how to build a simple Q&A application\\nover a text data source. Along the way we\u2019ll go over a typical Q&A\\narchitecture and highlight additional resources for more advanced Q&A techniques. We\u2019ll also see\\nhow LangSmith can help us trace and understand our application.\\nLangSmith will become increasingly helpful as our application grows in\\ncomplexity.\\nIf you\\'re already familiar with basic retrieval, you might also be interested in\\nthis high-level overview of different retrieval techniques.\\nNote: Here we focus on Q&A for unstructured data. If you are interested for RAG over structured data, check out our tutorial on doing question/answering over SQL data.\\nOverview\\u200b\\nA typical RAG application has two main components:\\nIndexing: a pipeline for ingesting data from a source and indexing it. This usually happens offline.\\nRetrieval and generation: the actual RAG chain, which takes the user query at run time and retrieves the relevant data from the index, then passes that to the model.\\nNote: the indexing portion of this tutorial will largely follow the semantic search tutorial.\\nThe most common full sequence from raw data to answer looks like:\\nIndexing\\u200b\\n\\nLoad: First we need to load our data. This is done with Document Loaders.\\nSplit: Text splitters break large Documents into smaller chunks. This is useful both for indexing data and passing it into a model, as large chunks are harder to search over and won\\'t fit in a model\\'s finite context window.\\nStore: We need somewhere to store and index our splits, so that they can be searched over later. This is often done using a VectorStore and Embeddings model.\\n\\n\\nRetrieval and generation\\u200b\\n\\nRetrieve: Given a user input, relevant splits are retrieved from storage using a Retriever.\\nGenerate: A ChatModel / LLM produces an answer using a prompt that includes both the question with the retrieved data\\n\\n\\nOnce we\\'ve indexed our data, we will use LangGraph as our orchestration framework to implement the retrieval and generation steps.\\nSetup\\u200b\\nJupyter Notebook\\u200b\\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebooks. Going through guides in an interactive environment is a great way to better understand them. See here for instructions on how to install.\\nInstallation\\u200b\\nThis tutorial requires these langchain dependencies:\\n\\nPipConda%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraphconda install langchain-text-splitters langchain-community langgraph -c conda-forge\\nFor more details, see our Installation guide.\\nLangSmith\\u200b\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\\nAs these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\\nThe best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nexport LANGSMITH_TRACING=\"true\"export LANGSMITH_API_KEY=\"...\"\\nOr, if in a notebook, you can set them with:\\nimport getpassimport osos.environ[\"LANGSMITH_TRACING\"] = \"true\"os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\\nComponents\\u200b\\nWe will need to select three components from LangChain\\'s suite of integrations.\\n\\nSelect chat model:Google Gemini\u25beOpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelllm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\\n\\nSelect embeddings model:OpenAI\u25beOpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get(\"OPENAI_API_KEY\"):  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\\n\\nSelect vector store:In-memory\u25beIn-memoryAstraDBChromaFAISSMilvusMongoDBPGVectorPineconeQdrantpip install -qU langchain-corefrom langchain_core.vectorstores import InMemoryVectorStorevector_store = InMemoryVectorStore(embeddings)\\nPreview\\u200b\\nIn this guide we\u2019ll build an app that answers questions about the website\\'s content. The specific website we will use is the LLM Powered Autonomous\\nAgents blog post\\nby Lilian Weng, which allows us to ask questions about the contents of\\nthe post.\\nWe can create a simple indexing pipeline and RAG chain to do this in ~50\\nlines of code.\\nimport bs4from langchain import hubfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_core.documents import Documentfrom langchain_text_splitters import RecursiveCharacterTextSplitterfrom langgraph.graph import START, StateGraphfrom typing_extensions import List, TypedDict# Load and chunk contents of the blogloader = WebBaseLoader(    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),    bs_kwargs=dict(        parse_only=bs4.SoupStrainer(            class_=(\"post-content\", \"post-title\", \"post-header\")        )    ),)docs = loader.load()text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)all_splits = text_splitter.split_documents(docs)# Index chunks_ = vector_store.add_documents(documents=all_splits)# Define prompt for question-answering# N.B. for non-US LangSmith endpoints, you may need to specify# api_url=\"https://api.smith.langchain.com\" in hub.pull.prompt = hub.pull(\"rlm/rag-prompt\")# Define state for applicationclass State(TypedDict):    question: str    context: List[Document]    answer: str# Define application stepsdef retrieve(state: State):    retrieved_docs = vector_store.similarity_search(state[\"question\"])    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\\\n\\\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}# Compile application and testgraph_builder = StateGraph(State).add_sequence([retrieve, generate])graph_builder.add_edge(START, \"retrieve\")graph = graph_builder.compile()API Reference:hub | WebBaseLoader | Document | RecursiveCharacterTextSplitter | StateGraph\\nresponse = graph.invoke({\"question\": \"What is Task Decomposition?\"})print(response[\"answer\"])\\nTask Decomposition is the process of breaking down a complicated task into smaller, manageable steps to facilitate easier execution and understanding. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) guide models to think step-by-step, allowing them to explore multiple reasoning possibilities. This method enhances performance on complex tasks and provides insight into the model\\'s thinking process.\\nCheck out the LangSmith\\ntrace.\\nDetailed walkthrough\\u200b\\nLet\u2019s go through the above code step-by-step to really understand what\u2019s\\ngoing on.\\n1. Indexing\\u200b\\nnoteThis section is an abbreviated version of the content in the semantic search tutorial.\\nIf you\\'re comfortable with document loaders, embeddings, and vector stores,\\nfeel free to skip to the next section on retrieval and generation.\\nLoading documents\\u200b\\nWe need to first load the blog post contents. We can use\\nDocumentLoaders\\nfor this, which are objects that load in data from a source and return a\\nlist of\\nDocument\\nobjects.\\nIn this case we\u2019ll use the\\nWebBaseLoader,\\nwhich uses urllib to load HTML from web URLs and BeautifulSoup to\\nparse it to text. We can customize the HTML -> text parsing by passing\\nin parameters into the BeautifulSoup parser via bs_kwargs (see\\nBeautifulSoup\\ndocs).\\nIn this case only HTML tags with class \u201cpost-content\u201d, \u201cpost-title\u201d, or\\n\u201cpost-header\u201d are relevant, so we\u2019ll remove all others.\\nimport bs4from langchain_community.document_loaders import WebBaseLoader# Only keep post title, headers, and content from the full HTML.bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))loader = WebBaseLoader(    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),    bs_kwargs={\"parse_only\": bs4_strainer},)docs = loader.load()assert len(docs) == 1print(f\"Total characters: {len(docs[0].page_content)}\")API Reference:WebBaseLoader\\nTotal characters: 43131\\nprint(docs[0].page_content[:500])\\n      LLM Powered Autonomous Agents    Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian WengBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.Agent System Overview#In\\nGo deeper\\u200b\\nDocumentLoader: Object that loads data from a source as list of Documents.\\n\\nDocs:\\nDetailed documentation on how to use DocumentLoaders.\\nIntegrations: 160+\\nintegrations to choose from.\\nInterface:\\nAPI reference for the base interface.\\n\\nSplitting documents\\u200b\\nOur loaded document is over 42k characters which is too long to fit\\ninto the context window of many models. Even for those models that could\\nfit the full post in their context window, models can struggle to find\\ninformation in very long inputs.\\nTo handle this we\u2019ll split the Document into chunks for embedding and\\nvector storage. This should help us retrieve only the most relevant parts\\nof the blog post at run time.\\nAs in the semantic search tutorial, we use a\\nRecursiveCharacterTextSplitter,\\nwhich will recursively split the document using common separators like\\nnew lines until each chunk is the appropriate size. This is the\\nrecommended text splitter for generic text use cases.\\nfrom langchain_text_splitters import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(    chunk_size=1000,  # chunk size (characters)    chunk_overlap=200,  # chunk overlap (characters)    add_start_index=True,  # track index in original document)all_splits = text_splitter.split_documents(docs)print(f\"Split blog post into {len(all_splits)} sub-documents.\")API Reference:RecursiveCharacterTextSplitter\\nSplit blog post into 66 sub-documents.\\nGo deeper\\u200b\\nTextSplitter: Object that splits a list of Documents into smaller\\nchunks. Subclass of DocumentTransformers.\\n\\nLearn more about splitting text using different methods by reading the how-to docs\\nCode (py or js)\\nScientific papers\\nInterface: API reference for the base interface.\\n\\nDocumentTransformer: Object that performs a transformation on a list\\nof Document objects.\\n\\nDocs: Detailed documentation on how to use DocumentTransformers\\nIntegrations\\nInterface: API reference for the base interface.\\n\\nStoring documents\\u200b\\nNow we need to index our 66 text chunks so that we can search over them\\nat runtime. Following the semantic search tutorial,\\nour approach is to embed the contents of each document split and insert these embeddings\\ninto a vector store. Given an input query, we can then use\\nvector search to retrieve relevant documents.\\nWe can embed and store all of our document splits in a single command\\nusing the vector store and embeddings model selected at the start of the tutorial.\\ndocument_ids = vector_store.add_documents(documents=all_splits)print(document_ids[:3])\\n[\\'07c18af6-ad58-479a-bfb1-d508033f9c64\\', \\'9000bf8e-1993-446f-8d4d-f4e507ba4b8f\\', \\'ba3b5d14-bed9-4f5f-88be-44c88aedc2e6\\']\\nGo deeper\\u200b\\nEmbeddings: Wrapper around a text embedding model, used for converting\\ntext to embeddings.\\n\\nDocs: Detailed documentation on how to use embeddings.\\nIntegrations: 30+ integrations to choose from.\\nInterface: API reference for the base interface.\\n\\nVectorStore: Wrapper around a vector database, used for storing and\\nquerying embeddings.\\n\\nDocs: Detailed documentation on how to use vector stores.\\nIntegrations: 40+ integrations to choose from.\\nInterface: API reference for the base interface.\\n\\nThis completes the Indexing portion of the pipeline. At this point\\nwe have a query-able vector store containing the chunked contents of our\\nblog post. Given a user question, we should ideally be able to return\\nthe snippets of the blog post that answer the question.\\n2. Retrieval and Generation\\u200b\\nNow let\u2019s write the actual application logic. We want to create a simple\\napplication that takes a user question, searches for documents relevant\\nto that question, passes the retrieved documents and initial question to\\na model, and returns an answer.\\nFor generation, we will use the chat model selected at the start of the tutorial.\\nWe\u2019ll use a prompt for RAG that is checked into the LangChain prompt hub\\n(here).\\nfrom langchain import hub# N.B. for non-US LangSmith endpoints, you may need to specify# api_url=\"https://api.smith.langchain.com\" in hub.pull.prompt = hub.pull(\"rlm/rag-prompt\")example_messages = prompt.invoke(    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}).to_messages()assert len(example_messages) == 1print(example_messages[0].content)API Reference:hub\\nYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.Question: (question goes here) Context: (context goes here) Answer:\\nWe\\'ll use LangGraph to tie together the retrieval and generation steps into a single application. This will bring a number of benefits:\\n\\nWe can define our application logic once and automatically support multiple invocation modes, including streaming, async, and batched calls.\\nWe get streamlined deployments via LangGraph Platform.\\nLangSmith will automatically trace the steps of our application together.\\nWe can easily add key features to our application, including persistence and human-in-the-loop approval, with minimal code changes.\\n\\nTo use LangGraph, we need to define three things:\\n\\nThe state of our application;\\nThe nodes of our application (i.e., application steps);\\nThe \"control flow\" of our application (e.g., the ordering of the steps).\\n\\nState:\\u200b\\nThe state of our application controls what data is input to the application, transferred between steps, and output by the application. It is typically a TypedDict, but can also be a Pydantic BaseModel.\\nFor a simple RAG application, we can just keep track of the input question, retrieved context, and generated answer:\\nfrom langchain_core.documents import Documentfrom typing_extensions import List, TypedDictclass State(TypedDict):    question: str    context: List[Document]    answer: strAPI Reference:Document\\nNodes (application steps)\\u200b\\nLet\\'s start with a simple sequence of two steps: retrieval and generation.\\ndef retrieve(state: State):    retrieved_docs = vector_store.similarity_search(state[\"question\"])    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\\\n\\\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}\\nOur retrieval step simply runs a similarity search using the input question, and the generation step formats the retrieved context and original question into a prompt for the chat model.\\nControl flow\\u200b\\nFinally, we compile our application into a single graph object. In this case, we are just connecting the retrieval and generation steps into a single sequence.\\nfrom langgraph.graph import START, StateGraphgraph_builder = StateGraph(State).add_sequence([retrieve, generate])graph_builder.add_edge(START, \"retrieve\")graph = graph_builder.compile()API Reference:StateGraph\\nLangGraph also comes with built-in utilities for visualizing the control flow of your application:\\nfrom IPython.display import Image, displaydisplay(Image(graph.get_graph().draw_mermaid_png()))\\n\\nDo I need to use LangGraph?LangGraph is not required to build a RAG application. Indeed, we can implement the same application logic through invocations of the individual components:question = \"...\"retrieved_docs = vector_store.similarity_search(question)docs_content = \"\\\\n\\\\n\".join(doc.page_content for doc in retrieved_docs)prompt = prompt.invoke({\"question\": question, \"context\": docs_content})answer = llm.invoke(prompt)The benefits of LangGraph include:\\nSupport for multiple invocation modes: this logic would need to be rewritten if we wanted to stream output tokens, or stream the results of individual steps;\\nAutomatic support for tracing via LangSmith and deployments via LangGraph Platform;\\nSupport for persistence, human-in-the-loop, and other features.\\nMany use-cases demand RAG in a conversational experience, such that a user can receive context-informed answers via a stateful conversation. As we will see in Part 2 of the tutorial, LangGraph\\'s management and persistence of state simplifies these applications enormously.\\nUsage\\u200b\\nLet\\'s test our application! LangGraph supports multiple invocation modes, including sync, async, and streaming.\\nInvoke:\\nresult = graph.invoke({\"question\": \"What is Task Decomposition?\"})print(f\"Context: {result[\\'context\\']}\\\\n\\\\n\")print(f\"Answer: {result[\\'answer\\']}\")\\nContext: [Document(id=\\'a42dc78b-8f76-472a-9e25-180508af74f3\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 1585}, page_content=\\'Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to \u201cthink step by step\u201d to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model\u2019s thinking process.\\'), Document(id=\\'c0e45887-d0b0-483d-821a-bb5d8316d51d\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 2192}, page_content=\\'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\'), Document(id=\\'4cc7f318-35f5-440f-a4a4-145b5f0b918d\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 29630}, page_content=\\'Resources:\\\\n1. Internet access for searches and information gathering.\\\\n2. Long Term memory management.\\\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\\\n4. File output.\\\\n\\\\nPerformance Evaluation:\\\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\\\n2. Constructively self-criticize your big-picture behavior constantly.\\\\n3. Reflect on past decisions and strategies to refine your approach.\\\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\'), Document(id=\\'f621ade4-9b0d-471f-a522-44eb5feeba0c\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 19373}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\\\nInstruction:\\\\n\\\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]Answer: Task decomposition is a technique used to break down complex tasks into smaller, manageable steps, allowing for more efficient problem-solving. This can be achieved through methods like chain of thought prompting or the tree of thoughts approach, which explores multiple reasoning possibilities at each step. It can be initiated through simple prompts, task-specific instructions, or human inputs.\\nStream steps:\\nfor step in graph.stream(    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"):    print(f\"{step}\\\\n\\\\n----------------\\\\n\")\\n{\\'retrieve\\': {\\'context\\': [Document(id=\\'a42dc78b-8f76-472a-9e25-180508af74f3\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 1585}, page_content=\\'Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to \u201cthink step by step\u201d to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model\u2019s thinking process.\\'), Document(id=\\'c0e45887-d0b0-483d-821a-bb5d8316d51d\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 2192}, page_content=\\'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\'), Document(id=\\'4cc7f318-35f5-440f-a4a4-145b5f0b918d\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 29630}, page_content=\\'Resources:\\\\n1. Internet access for searches and information gathering.\\\\n2. Long Term memory management.\\\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\\\n4. File output.\\\\n\\\\nPerformance Evaluation:\\\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\\\n2. Constructively self-criticize your big-picture behavior constantly.\\\\n3. Reflect on past decisions and strategies to refine your approach.\\\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\'), Document(id=\\'f621ade4-9b0d-471f-a522-44eb5feeba0c\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 19373}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\\\nInstruction:\\\\n\\\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]}}----------------{\\'generate\\': {\\'answer\\': \\'Task decomposition is the process of breaking down a complex task into smaller, more manageable steps. This technique, often enhanced by methods like Chain of Thought (CoT) or Tree of Thoughts, allows models to reason through tasks systematically and improves performance by clarifying the thought process. It can be achieved through simple prompts, task-specific instructions, or human inputs.\\'}}----------------\\nStream tokens:\\nfor message, metadata in graph.stream(    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"):    print(message.content, end=\"|\")\\n|Task| decomposition| is| the| process| of| breaking| down| complex| tasks| into| smaller|,| more| manageable| steps|.| It| can| be| achieved| through| techniques| like| Chain| of| Thought| (|Co|T|)| prompting|,| which| encourages| the| model| to| think| step| by| step|,| or| through| more| structured| methods| like| the| Tree| of| Thoughts|.| This| approach| not| only| simplifies| task| execution| but| also| provides| insights| into| the| model|\\'s| reasoning| process|.||\\ntipFor async invocations, use:result = await graph.ainvoke(...)andasync for step in graph.astream(...):\\nReturning sources\\u200b\\nNote that by storing the retrieved context in the state of the graph, we recover sources for the model\\'s generated answer in the \"context\" field of the state. See this guide on returning sources for more detail.\\nGo deeper\\u200b\\nChat models take in a sequence of messages and return a message.\\n\\nDocs\\nIntegrations: 25+ integrations to choose from.\\nInterface: API reference for the base interface.\\n\\nCustomizing the prompt\\nAs shown above, we can load prompts (e.g., this RAG\\nprompt) from the prompt\\nhub. The prompt can also be easily customized. For example:\\nfrom langchain_core.prompts import PromptTemplatetemplate = \"\"\"Use the following pieces of context to answer the question at the end.If you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.Use three sentences maximum and keep the answer as concise as possible.Always say \"thanks for asking!\" at the end of the answer.{context}Question: {question}Helpful Answer:\"\"\"custom_rag_prompt = PromptTemplate.from_template(template)API Reference:PromptTemplate\\nQuery analysis\\u200b\\nSo far, we are executing the retrieval using the raw input query. However, there are some advantages to allowing a model to generate the query for retrieval purposes. For example:\\n\\nIn addition to semantic search, we can build in structured filters (e.g., \"Find documents since the year 2020.\");\\nThe model can rewrite user queries, which may be multifaceted or include irrelevant language, into more effective search queries.\\n\\nQuery analysis employs models to transform or construct optimized search queries from raw user input. We can easily incorporate a query analysis step into our application. For illustrative purposes, let\\'s add some metadata to the documents in our vector store. We will add some (contrived) sections to the document which we can filter on later.\\ntotal_documents = len(all_splits)third = total_documents // 3for i, document in enumerate(all_splits):    if i < third:        document.metadata[\"section\"] = \"beginning\"    elif i < 2 * third:        document.metadata[\"section\"] = \"middle\"    else:        document.metadata[\"section\"] = \"end\"all_splits[0].metadata\\n{\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 8, \\'section\\': \\'beginning\\'}\\nWe will need to update the documents in our vector store. We will use a simple InMemoryVectorStore for this, as we will use some of its specific features (i.e., metadata filtering). Refer to the vector store integration documentation for relevant features of your chosen vector store.\\nfrom langchain_core.vectorstores import InMemoryVectorStorevector_store = InMemoryVectorStore(embeddings)_ = vector_store.add_documents(all_splits)API Reference:InMemoryVectorStore\\nLet\\'s next define a schema for our search query. We will use structured output for this purpose. Here we define a query as containing a string query and a document section (either \"beginning\", \"middle\", or \"end\"), but this can be defined however you like.\\nfrom typing import Literalfrom typing_extensions import Annotatedclass Search(TypedDict):    \"\"\"Search query.\"\"\"    query: Annotated[str, ..., \"Search query to run.\"]    section: Annotated[        Literal[\"beginning\", \"middle\", \"end\"],        ...,        \"Section to query.\",    ]\\nFinally, we add a step to our LangGraph application to generate a query from the user\\'s raw input:\\nclass State(TypedDict):    question: str    query: Search    context: List[Document]    answer: strdef analyze_query(state: State):    structured_llm = llm.with_structured_output(Search)    query = structured_llm.invoke(state[\"question\"])    return {\"query\": query}def retrieve(state: State):    query = state[\"query\"]    retrieved_docs = vector_store.similarity_search(        query[\"query\"],        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],    )    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\\\n\\\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])graph_builder.add_edge(START, \"analyze_query\")graph = graph_builder.compile()\\nFull Code:from typing import Literalimport bs4from langchain import hubfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_core.documents import Documentfrom langchain_core.vectorstores import InMemoryVectorStorefrom langchain_text_splitters import RecursiveCharacterTextSplitterfrom langgraph.graph import START, StateGraphfrom typing_extensions import Annotated, List, TypedDict# Load and chunk contents of the blogloader = WebBaseLoader(    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),    bs_kwargs=dict(        parse_only=bs4.SoupStrainer(            class_=(\"post-content\", \"post-title\", \"post-header\")        )    ),)docs = loader.load()text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)all_splits = text_splitter.split_documents(docs)# Update metadata (illustration purposes)total_documents = len(all_splits)third = total_documents // 3for i, document in enumerate(all_splits):    if i < third:        document.metadata[\"section\"] = \"beginning\"    elif i < 2 * third:        document.metadata[\"section\"] = \"middle\"    else:        document.metadata[\"section\"] = \"end\"# Index chunksvector_store = InMemoryVectorStore(embeddings)_ = vector_store.add_documents(all_splits)# Define schema for searchclass Search(TypedDict):    \"\"\"Search query.\"\"\"    query: Annotated[str, ..., \"Search query to run.\"]    section: Annotated[        Literal[\"beginning\", \"middle\", \"end\"],        ...,        \"Section to query.\",    ]# Define prompt for question-answeringprompt = hub.pull(\"rlm/rag-prompt\")# Define state for applicationclass State(TypedDict):    question: str    query: Search    context: List[Document]    answer: strdef analyze_query(state: State):    structured_llm = llm.with_structured_output(Search)    query = structured_llm.invoke(state[\"question\"])    return {\"query\": query}def retrieve(state: State):    query = state[\"query\"]    retrieved_docs = vector_store.similarity_search(        query[\"query\"],        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],    )    return {\"context\": retrieved_docs}def generate(state: State):    docs_content = \"\\\\n\\\\n\".join(doc.page_content for doc in state[\"context\"])    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})    response = llm.invoke(messages)    return {\"answer\": response.content}graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])graph_builder.add_edge(START, \"analyze_query\")graph = graph_builder.compile()API Reference:hub | WebBaseLoader | Document | InMemoryVectorStore | RecursiveCharacterTextSplitter | StateGraph\\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\\n\\nWe can test our implementation by specifically asking for context from the end of the post. Note that the model includes different information in its answer.\\nfor step in graph.stream(    {\"question\": \"What does the end of the post say about Task Decomposition?\"},    stream_mode=\"updates\",):    print(f\"{step}\\\\n\\\\n----------------\\\\n\")\\n{\\'analyze_query\\': {\\'query\\': {\\'query\\': \\'Task Decomposition\\', \\'section\\': \\'end\\'}}}----------------{\\'retrieve\\': {\\'context\\': [Document(id=\\'d6cef137-e1e8-4ddc-91dc-b62bd33c6020\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 39221, \\'section\\': \\'end\\'}, page_content=\\'Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\'), Document(id=\\'d1834ae1-eb6a-43d7-a023-08dfa5028799\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 39086, \\'section\\': \\'end\\'}, page_content=\\'}\\\\n]\\\\nChallenges#\\\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\'), Document(id=\\'ca7f06e4-2c2e-4788-9a81-2418d82213d9\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 32942, \\'section\\': \\'end\\'}, page_content=\\'}\\\\n]\\\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\\\nSystem message:\\'), Document(id=\\'1fcc2736-30f4-4ef6-90f2-c64af92118cb\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 35127, \\'section\\': \\'end\\'}, page_content=\\'\"content\": \"You will get instructions for code to write.\\\\\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\\\\\n\\\\\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\\\\\n\\\\\\\\nThen you will output the content of each file including ALL code.\\\\\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\\\\\nFILENAME is the lowercase file name including the file extension,\\\\\\\\nLANG is the markup code block language for the code\\\\\\'s language, and CODE is the code:\\\\\\\\n\\\\\\\\nFILENAME\\\\\\\\n\\\\`\\\\`\\\\`LANG\\\\\\\\nCODE\\\\\\\\n\\\\`\\\\`\\\\`\\\\\\\\n\\\\\\\\nYou will start with the \\\\\\\\\"entrypoint\\\\\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\\\\\nPlease\\')]}}----------------{\\'generate\\': {\\'answer\\': \\'The end of the post highlights that task decomposition faces challenges in long-term planning and adapting to unexpected errors. LLMs struggle with adjusting their plans, making them less robust compared to humans who learn from trial and error. This indicates a limitation in effectively exploring the solution space and handling complex tasks.\\'}}----------------\\nIn both the streamed steps and the LangSmith trace, we can now observe the structured query that was fed into the retrieval step.\\nQuery Analysis is a rich problem with a wide range of approaches. Refer to the how-to guides for more examples.\\nNext steps\\u200b\\nWe\\'ve covered the steps to build a basic Q&A app over data:\\n\\nLoading data with a Document Loader\\nChunking the indexed data with a Text Splitter to make it more easily usable by a model\\nEmbedding the data and storing the data in a vectorstore\\nRetrieving the previously stored chunks in response to incoming questions\\nGenerating an answer using the retrieved chunks as context.\\n\\nIn Part 2 of the tutorial, we will extend the implementation here to accommodate conversation-style interactions and multi-step retrieval processes.\\nFurther reading:\\n\\nReturn sources: Learn how to return source documents\\nStreaming: Learn how to stream outputs and intermediate steps\\nAdd chat history: Learn how to add chat history to your app\\nRetrieval conceptual guide: A high-level overview of specific retrieval techniques\\nEdit this pagePreviousTaggingNextBuild a semantic search engineOverviewIndexingRetrieval and generationSetupJupyter NotebookInstallationLangSmithComponentsPreviewDetailed walkthrough1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationQuery analysisNext stepsCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nGraph RAG | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGreenNodeGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)SurrealDBNebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTensorlakeTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksIBM Db2 Vector Store and Vector SearchDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBVectorStoreTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientGreenNodeHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsRetrieversGraph RAGOn this pageGraph RAG\\nThis guide provides an introduction to Graph RAG. For detailed documentation of all\\nsupported features and configurations, refer to the\\nGraph RAG Project Page.\\nOverview\\u200b\\nThe GraphRetriever from the langchain-graph-retriever package provides a LangChain\\nretriever that combines unstructured similarity search\\non vectors with structured traversal of metadata properties. This enables graph-based\\nretrieval over an existing vector store.\\nIntegration details\\u200b\\nRetrieverSourcePyPI PackageLatestProject PageGraphRetrievergithub.com/datastax/graph-raglangchain-graph-retrieverGraph RAG\\nBenefits\\u200b\\n\\n\\nLink based on existing metadata:\\nUse existing metadata fields without additional processing. Retrieve more from an\\nexisting vector store!\\n\\n\\nChange links on demand:\\nEdges can be specified on-the-fly, allowing different relationships to be traversed\\nbased on the question.\\n\\n\\nPluggable Traversal Strategies:\\nUse built-in traversal strategies like Eager or MMR, or define custom logic to select\\nwhich nodes to explore.\\n\\n\\nBroad compatibility:\\nAdapters are available for a variety of vector stores with support for additional\\nstores easily added.\\n\\n\\nSetup\\u200b\\nInstallation\\u200b\\nThis retriever lives in the langchain-graph-retriever package.\\npip install -qU langchain-graph-retriever\\nInstantiation\\u200b\\nThe following examples will show how to perform graph traversal over some sample\\nDocuments about animals.\\nPrerequisites\\u200b\\nToggle for Details\\n\\nEnsure you have Python 3.10+ installed\\n\\n\\nInstall the following package that provides sample data.\\npip install -qU graph_rag_example_helpers\\n\\n\\nDownload the test documents:\\nfrom graph_rag_example_helpers.datasets.animals import fetch_documentsanimals = fetch_documents()\\n\\n\\nSelect embeddings model:OpenAI\u25beOpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get(\"OPENAI_API_KEY\"):  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\\n\\n\\nPopulating the Vector store\\u200b\\nThis section shows how to populate a variety of vector stores with the sample data.\\nFor help on choosing one of the vector stores below, or to add support for your\\nvector store, consult the documentation about\\nAdapters and Supported Stores.\\nAstraDBApache CassandraOpenSearchChromaInMemoryInstall the langchain-graph-retriever package with the astra extra:pip install \"langchain-graph-retriever[astra]\"Then create a vector store and load the test documents:from langchain_astradb import AstraDBVectorStorevector_store = AstraDBVectorStore.from_documents(    documents=animals,    embedding=embeddings,    collection_name=\"animals\",    api_endpoint=ASTRA_DB_API_ENDPOINT,    token=ASTRA_DB_APPLICATION_TOKEN,)For the ASTRA_DB_API_ENDPOINT and ASTRA_DB_APPLICATION_TOKEN credentials,\\nconsult the AstraDB Vector Store Guide.noteFor faster initial testing, consider using the InMemory Vector Store.Install the langchain-graph-retriever package with the cassandra extra:pip install \"langchain-graph-retriever[cassandra]\"Then create a vector store and load the test documents:from langchain_community.vectorstores.cassandra import Cassandrafrom langchain_graph_retriever.transformers import ShreddingTransformervector_store = Cassandra.from_documents(    documents=list(ShreddingTransformer().transform_documents(animals)),    embedding=embeddings,    table_name=\"animals\",)For help creating a Cassandra connection, consult the\\nApache Cassandra Vector Store GuidenoteApache Cassandra doesn\\'t support searching in nested metadata. Because of this\\nit is necessary to use the ShreddingTransformer\\nwhen inserting documents.Install the langchain-graph-retriever package with the opensearch extra:pip install \"langchain-graph-retriever[opensearch]\"Then create a vector store and load the test documents:from langchain_community.vectorstores import OpenSearchVectorSearchvector_store = OpenSearchVectorSearch.from_documents(    documents=animals,    embedding=embeddings,    engine=\"faiss\",    index_name=\"animals\",    opensearch_url=OPEN_SEARCH_URL,    bulk_size=500,)For help creating an OpenSearch connection, consult the\\nOpenSearch Vector Store Guide.Install the langchain-graph-retriever package with the chroma extra:pip install \"langchain-graph-retriever[chroma]\"Then create a vector store and load the test documents:from langchain_chroma.vectorstores import Chromafrom langchain_graph_retriever.transformers import ShreddingTransformervector_store = Chroma.from_documents(    documents=list(ShreddingTransformer().transform_documents(animals)),    embedding=embeddings,    collection_name=\"animals\",)For help creating an Chroma connection, consult the\\nChroma Vector Store Guide.noteChroma doesn\\'t support searching in nested metadata. Because of this\\nit is necessary to use the ShreddingTransformer\\nwhen inserting documents.Install the langchain-graph-retriever package:pip install \"langchain-graph-retriever\"Then create a vector store and load the test documents:from langchain_core.vectorstores import InMemoryVectorStorevector_store = InMemoryVectorStore.from_documents(    documents=animals,    embedding=embeddings,)tipUsing the InMemoryVectorStore is the fastest way to get started with Graph RAG\\nbut it isn\\'t recommended for production use. Instead it is recommended to use\\nAstraDB or OpenSearch.\\nGraph Traversal\\u200b\\nThis graph retriever starts with a single animal that best matches the query, then\\ntraverses to other animals sharing the same habitat and/or origin.\\nfrom graph_retriever.strategies import Eagerfrom langchain_graph_retriever import GraphRetrievertraversal_retriever = GraphRetriever(    store = vector_store,    edges = [(\"habitat\", \"habitat\"), (\"origin\", \"origin\")],    strategy = Eager(k=5, start_k=1, max_depth=2),)\\nThe above creates a graph traversing retriever that starts with the nearest\\nanimal (start_k=1), retrieves 5 documents (k=5) and limits the search to documents\\nthat are at most 2 steps away from the first animal (max_depth=2).\\nThe edges define how metadata values can be used for traversal. In this case, every\\nanimal is connected to other animals with the same habitat and/or origin.\\nresults = traversal_retriever.invoke(\"what animals could be found near a capybara?\")for doc in results:    print(f\"{doc.id}: {doc.page_content}\")\\ncapybara: capybaras are the largest rodents in the world and are highly social animals.heron: herons are wading birds known for their long legs and necks, often seen near water.crocodile: crocodiles are large reptiles with powerful jaws and a long lifespan, often living over 70 years.frog: frogs are amphibians known for their jumping ability and croaking sounds.duck: ducks are waterfowl birds known for their webbed feet and quacking sounds.\\nGraph traversal improves retrieval quality by leveraging structured relationships in\\nthe data. Unlike standard similarity search (see below), it provides a clear,\\nexplainable rationale for why documents are selected.\\nIn this case, the documents capybara, heron, frog, crocodile, and newt all\\nshare the same habitat=wetlands, as defined by their metadata. This should increase\\nDocument Relevance and the quality of the answer from the LLM.\\nComparison to Standard Retrieval\\u200b\\nWhen max_depth=0, the graph traversing retriever behaves like a standard retriever:\\nstandard_retriever = GraphRetriever(    store = vector_store,    edges = [(\"habitat\", \"habitat\"), (\"origin\", \"origin\")],    strategy = Eager(k=5, start_k=5, max_depth=0),)\\nThis creates a retriever that starts with the nearest 5 animals (start_k=5),\\nand returns them without any traversal (max_depth=0). The edge definitions\\nare ignored in this case.\\nThis is essentially the same as:\\nstandard_retriever = vector_store.as_retriever(search_kwargs={\"k\":5})\\nFor either case, invoking the retriever returns:\\nresults = standard_retriever.invoke(\"what animals could be found near a capybara?\")for doc in results:    print(f\"{doc.id}: {doc.page_content}\")\\ncapybara: capybaras are the largest rodents in the world and are highly social animals.iguana: iguanas are large herbivorous lizards often found basking in trees and near water.guinea pig: guinea pigs are small rodents often kept as pets due to their gentle and social nature.hippopotamus: hippopotamuses are large semi-aquatic mammals known for their massive size and territorial behavior.boar: boars are wild relatives of pigs, known for their tough hides and tusks.\\nThese documents are joined based on similarity alone. Any structural data that existed\\nin the store is ignored. As compared to graph retrieval, this can decrease Document\\nRelevance because the returned results have a lower chance of being helpful to answer\\nthe query.\\nUsage\\u200b\\nFollowing the examples above, .invoke is used to initiate retrieval on a query.\\nUse within a chain\\u200b\\nLike other retrievers, GraphRetriever can be incorporated into LLM applications\\nvia chains.\\nSelect chat model:Google Gemini\u25beOpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelllm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\\nfrom langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.runnables import RunnablePassthroughprompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based only on the context provided.Context: {context}Question: {question}\"\"\")def format_docs(docs):    return \"\\\\n\\\\n\".join(f\"text: {doc.page_content} metadata: {doc.metadata}\" for doc in docs)chain = (    {\"context\": traversal_retriever | format_docs, \"question\": RunnablePassthrough()}    | prompt    | llm    | StrOutputParser())API Reference:StrOutputParser | ChatPromptTemplate | RunnablePassthrough\\nchain.invoke(\"what animals could be found near a capybara?\")\\nAnimals that could be found near a capybara include herons, crocodiles, frogs,and ducks, as they all inhabit wetlands.\\nAPI reference\\u200b\\nTo explore all available parameters and advanced configurations, refer to the\\nGraph RAG API reference.\\nRelated\\u200b\\n\\nRetriever conceptual guide\\nRetriever how-to guides\\nEdit this pagePreviousGoogle Vertex AI SearchNextGreenNodeOverviewIntegration detailsBenefitsSetupInstallationInstantiationPrerequisitesPopulating the Vector storeGraph TraversalComparison to Standard RetrievalUsageUse within a chainAPI referenceRelatedCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\nAzureOpenAIEmbeddings | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGreenNodeGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)SurrealDBNebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTensorlakeTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksIBM Db2 Vector Store and Vector SearchDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBVectorStoreTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientGreenNodeHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsEmbedding modelsAzureOpenAIOn this pageAzureOpenAIEmbeddings\\nThis will help you get started with AzureOpenAI embedding models using LangChain. For detailed documentation on AzureOpenAIEmbeddings features and configuration options, please refer to the API reference.\\nOverview\\u200b\\nIntegration details\\u200b\\n\\nProviderPackageAzureOpenAIlangchain-openai\\nSetup\\u200b\\nTo access AzureOpenAI embedding models you\\'ll need to create an Azure account, get an API key, and install the langchain-openai integration package.\\nCredentials\\u200b\\nYou\u2019ll need to have an Azure OpenAI instance deployed. You can deploy a version on Azure Portal following this guide.\\nOnce you have your instance running, make sure you have the name of your instance and key. You can find the key in the Azure Portal, under the \u201cKeys and Endpoint\u201d section of your instance.\\nAZURE_OPENAI_ENDPOINT=<YOUR API ENDPOINT>AZURE_OPENAI_API_KEY=<YOUR_KEY>AZURE_OPENAI_API_VERSION=\"2024-02-01\"\\nimport getpassimport osif not os.getenv(\"AZURE_OPENAI_API_KEY\"):    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(        \"Enter your AzureOpenAI API key: \"    )\\nTo enable automated tracing of your model calls, set your LangSmith API key:\\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\\nInstallation\\u200b\\nThe LangChain AzureOpenAI integration lives in the langchain-openai package:\\n%pip install -qU langchain-openai\\nInstantiation\\u200b\\nNow we can instantiate our model object and generate chat completions:\\nfrom langchain_openai import AzureOpenAIEmbeddingsembeddings = AzureOpenAIEmbeddings(    model=\"text-embedding-3-large\",    # dimensions: Optional[int] = None, # Can specify dimensions with new text-embedding-3 models    # azure_endpoint=\"https://<your-endpoint>.openai.azure.com/\", If not provided, will read env variable AZURE_OPENAI_ENDPOINT    # api_key=... # Can provide an API key directly. If missing read env variable AZURE_OPENAI_API_KEY    # openai_api_version=..., # If not provided, will read env variable AZURE_OPENAI_API_VERSION)API Reference:AzureOpenAIEmbeddings\\nIndexing and Retrieval\\u200b\\nEmbedding models are often used in retrieval-augmented generation (RAG) flows, both as part of indexing data as well as later retrieving it. For more detailed instructions, please see our RAG tutorials.\\nBelow, see how to index and retrieve data using the embeddings object we initialized above. In this example, we will index and retrieve a sample document in the InMemoryVectorStore.\\n# Create a vector store with a sample textfrom langchain_core.vectorstores import InMemoryVectorStoretext = \"LangChain is the framework for building context-aware reasoning applications\"vectorstore = InMemoryVectorStore.from_texts(    [text],    embedding=embeddings,)# Use the vectorstore as a retrieverretriever = vectorstore.as_retriever()# Retrieve the most similar textretrieved_documents = retriever.invoke(\"What is LangChain?\")# show the retrieved document\\'s contentretrieved_documents[0].page_contentAPI Reference:InMemoryVectorStore\\n\\'LangChain is the framework for building context-aware reasoning applications\\'\\nDirect Usage\\u200b\\nUnder the hood, the vectorstore and retriever implementations are calling embeddings.embed_documents(...) and embeddings.embed_query(...) to create embeddings for the text(s) used in from_texts and retrieval invoke operations, respectively.\\nYou can directly call these methods to get embeddings for your own use cases.\\nEmbed single texts\\u200b\\nYou can embed single texts or documents with embed_query:\\nsingle_vector = embeddings.embed_query(text)print(str(single_vector)[:100])  # Show the first 100 characters of the vector\\n[-0.0011676070280373096, 0.007125577889382839, -0.014674457721412182, -0.034061674028635025, 0.01128\\nEmbed multiple texts\\u200b\\nYou can embed multiple texts with embed_documents:\\ntext2 = (    \"LangGraph is a library for building stateful, multi-actor applications with LLMs\")two_vectors = embeddings.embed_documents([text, text2])for vector in two_vectors:    print(str(vector)[:100])  # Show the first 100 characters of the vector\\n[-0.0011966148158535361, 0.007160289213061333, -0.014659193344414234, -0.03403077274560928, 0.011280[-0.005595256108790636, 0.016757294535636902, -0.011055258102715015, -0.031094247475266457, -0.00363\\nAPI Reference\\u200b\\nFor detailed documentation on AzureOpenAIEmbeddings features and configuration options, please refer to the API reference.\\nRelated\\u200b\\n\\nEmbedding model conceptual guide\\nEmbedding model how-to guides\\nEdit this pagePreviousAwaDBNextBaichuan Text EmbeddingsOverviewIntegration detailsSetupCredentialsInstallationInstantiationIndexing and RetrievalDirect UsageEmbed single textsEmbed multiple textsAPI ReferenceRelatedCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\\n\\n' annotations=None meta=None"
        ]
      }
    ]
  }
]